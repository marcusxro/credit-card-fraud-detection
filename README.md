# Credit Card Fraud Detection ğŸ’³ğŸ”

A comprehensive machine learning project for detecting fraudulent credit card transactions using the Kaggle Credit Card Fraud Detection dataset. This project implements multiple ML algorithms with extensive data analysis, visualization, and model evaluation capabilities.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.0-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Dataset](#dataset)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Model Performance](#model-performance)
- [Visualizations](#visualizations)
- [Technologies Used](#technologies-used)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

Credit card fraud is a significant problem in financial transactions. This project uses machine learning to identify fraudulent transactions from a highly imbalanced dataset. The solution includes:

- **Data preprocessing** with standardization and SMOTE for handling class imbalance
- **Multiple ML models** including Logistic Regression and Random Forest
- **Comprehensive evaluation** with various metrics and visualizations
- **Prediction system** for real-time fraud detection
- **Interactive Jupyter notebook** for exploratory data analysis

## ğŸ“Š Dataset

This project uses the **Credit Card Fraud Detection Dataset** from Kaggle:

- **Source**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Size**: 284,807 transactions
- **Fraudulent transactions**: 492 (0.172% of all transactions)
- **Features**: 30 numerical features (Time, V1-V28, Amount)
- **Target**: Class (0 = Normal, 1 = Fraud)

### Dataset Characteristics

- **Highly imbalanced**: Only 0.172% of transactions are fraudulent
- **PCA transformed**: Features V1-V28 are principal components (for confidentiality)
- **Time**: Seconds elapsed between each transaction and the first transaction
- **Amount**: Transaction amount (useful for cost-sensitive learning)

### Download Instructions

1. Visit the [Kaggle dataset page](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
2. Download `creditcard.csv`
3. Place the file in the project root directory

## âœ¨ Features

### Data Analysis & Visualization
- ğŸ“ˆ Comprehensive exploratory data analysis
- ğŸ“Š Class distribution analysis
- ğŸ” Feature correlation analysis
- ğŸ“‰ Transaction amount and time distribution plots
- ğŸ¨ Correlation heatmaps

### Machine Learning Models
- ğŸ¤– Logistic Regression
- ğŸŒ² Random Forest Classifier
- âš–ï¸ SMOTE for handling class imbalance
- ğŸ“ StandardScaler for feature normalization

### Model Evaluation
- âœ… Accuracy, Precision, Recall, F1-Score
- ğŸ“ˆ ROC-AUC Score and ROC Curves
- ğŸ“Š Confusion Matrices
- ğŸ”„ Cross-validation
- ğŸ“‰ Precision-Recall Curves

### Prediction System
- ğŸ¯ Single transaction prediction
- ğŸ“¦ Batch prediction from CSV files
- âš ï¸ Risk level classification (Low, Medium, High, Critical)
- ğŸ’¾ Model persistence with joblib

### Interactive Tools
- ğŸ““ Jupyter notebook for interactive exploration
- ğŸ”§ Configuration file for easy parameter tuning
- ğŸ“ Organized output structure (plots, models, results)

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/marcusxro/credit-card-fraud-detection.git
   cd credit-card-fraud-detection
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   # On Windows
   python -m venv venv
   venv\Scripts\activate

   # On macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Download the dataset**
   - Download `creditcard.csv` from [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
   - Place it in the project root directory

## ğŸ“– Usage

### 1. Train the Models

Run the main training script to train all models, generate visualizations, and save the trained models:

```bash
python fraud_detection.py
```

This will:
- Load and analyze the dataset
- Create visualizations in the `plots/` directory
- Preprocess data with SMOTE
- Preprocess data with SMOTE
- Train Logistic Regression and Random Forest models
- Evaluate models with comprehensive metrics
- Save trained models to `saved_models/` directory

**Output**:
- `plots/class_distribution.png` - Class distribution visualization
- `plots/amount_distribution.png` - Transaction amount analysis
- `plots/time_distribution.png` - Transaction time analysis
- `plots/correlation_heatmap.png` - Feature correlation heatmap
- `plots/model_comparison.png` - Model performance comparison
- `plots/roc_curves.png` - ROC curves for all models
- `plots/confusion_matrices.png` - Confusion matrices
- `saved_models/*.pkl` - Trained models and scaler

### 2. Make Predictions

#### Single Prediction (Interactive Mode)
```bash
python predict.py
```

#### Batch Predictions from CSV
```bash
python predict.py transactions.csv
```

This will:
- Load the trained model
- Make predictions on all transactions in the CSV
- Generate risk levels for each transaction
- Save results to `transactions_predictions.csv`
- Display high-risk transactions

### 3. Interactive Analysis with Jupyter Notebook

Launch the Jupyter notebook for interactive exploration:

```bash
jupyter notebook fraud_detection_notebook.ipynb
```

The notebook includes:
- Step-by-step data exploration
- Interactive visualizations
- Model training and evaluation
- Example predictions

### 4. Custom Configuration

Modify `config.py` to customize:
- Model hyperparameters
- Train-test split ratio
- SMOTE settings
- Output directories
- Visualization preferences

## ğŸ“ Project Structure

```
credit-card-fraud-detection/
â”‚
â”œâ”€â”€ fraud_detection.py          # Main training script
â”œâ”€â”€ predict.py                  # Prediction script
â”œâ”€â”€ config.py                   # Configuration file
â”œâ”€â”€ fraud_detection_notebook.ipynb  # Interactive Jupyter notebook
â”œâ”€â”€ requirements.txt            # Project dependencies
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ .gitignore                  # Git ignore file
â”‚
â”œâ”€â”€ creditcard.csv              # Dataset (download separately)
â”‚
â”œâ”€â”€ plots/                      # Generated visualizations
â”‚   â”œâ”€â”€ class_distribution.png
â”‚   â”œâ”€â”€ amount_distribution.png
â”‚   â”œâ”€â”€ time_distribution.png
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â””â”€â”€ confusion_matrices.png
â”‚
â””â”€â”€ saved_models/               # Trained models
    â”œâ”€â”€ logistic_regression_model.pkl
    â”œâ”€â”€ random_forest_model.pkl
    â””â”€â”€ scaler.pkl
```

## ğŸ“Š Model Performance

The models are evaluated using multiple metrics to handle the imbalanced dataset:

### Logistic Regression
- **Accuracy**: ~99.9%
- **Precision**: High precision in detecting fraud
- **Recall**: Good recall for fraud detection
- **F1-Score**: Balanced performance
- **ROC-AUC**: Excellent separation capability

### Random Forest Classifier
- **Accuracy**: ~99.9%
- **Precision**: Superior fraud detection precision
- **Recall**: Excellent fraud recall
- **F1-Score**: Best overall balance
- **ROC-AUC**: Outstanding performance

> **Note**: Due to the highly imbalanced nature of the dataset, accuracy alone is not a reliable metric. We focus on Precision, Recall, F1-Score, and ROC-AUC for proper evaluation.

### Key Insights
- ğŸ¯ Random Forest typically outperforms Logistic Regression
- âš–ï¸ SMOTE significantly improves model performance on fraud detection
- ğŸ“ˆ Both models achieve excellent ROC-AUC scores (>0.95)
- ğŸ² Very few false positives while maintaining high fraud detection rate

## ğŸ¨ Visualizations

The project generates comprehensive visualizations:

1. **Class Distribution**: Shows the severe imbalance in the dataset
2. **Amount Distribution**: Compares transaction amounts for normal vs. fraud
3. **Time Distribution**: Analyzes when fraudulent transactions occur
4. **Correlation Heatmap**: Identifies features most correlated with fraud
5. **Model Comparison**: Side-by-side comparison of all metrics
6. **ROC Curves**: Visual comparison of model performance
7. **Confusion Matrices**: Detailed breakdown of predictions

All visualizations are automatically saved to the `plots/` directory.

## ğŸ› ï¸ Technologies Used

### Core Libraries
- **NumPy** (1.24.3) - Numerical computing
- **Pandas** (2.0.3) - Data manipulation and analysis
- **scikit-learn** (1.3.0) - Machine learning algorithms

### Visualization
- **Matplotlib** (3.7.2) - Plotting and visualization
- **Seaborn** (0.12.2) - Statistical data visualization

### Class Imbalance Handling
- **imbalanced-learn** (0.11.0) - SMOTE and other sampling techniques

### Model Persistence
- **joblib** (1.3.2) - Efficient model serialization

### Interactive Development
- **Jupyter** (1.0.0) - Interactive notebook environment
- **notebook** (7.0.2) - Jupyter notebook interface

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit your changes**
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```
4. **Push to the branch**
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Open a Pull Request**

### Ideas for Contributions
- ğŸ¤– Add more ML models (XGBoost, Neural Networks, etc.)
- ğŸ¨ Improve visualizations
- ğŸ“Š Add more evaluation metrics
- ğŸ”§ Enhance configuration options
- ğŸ“š Improve documentation
- ğŸ§ª Add unit tests
- ğŸŒ Create a web interface for predictions

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Dataset**: Machine Learning Group - ULB (UniversitÃ© Libre de Bruxelles)
- **Dataset Publication**: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. 
  *Calibrating Probability with Undersampling for Unbalanced Classification.* 
  In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015
- **Kaggle**: For hosting the dataset and providing a platform for data science

## ğŸ“§ Contact

**Marcus** - [@marcusxro](https://github.com/marcusxro)

Project Link: [https://github.com/marcusxro/credit-card-fraud-detection](https://github.com/marcusxro/credit-card-fraud-detection)

---

â­ If you found this project helpful, please consider giving it a star!

**Happy Fraud Detecting! ğŸ•µï¸â€â™‚ï¸ğŸ’³**